#!/bin/bash
set -e

echo "=== RTX 5090 vLLM ë¹Œë“œ (ì‘ë™ í™•ì¸ëœ ì„¤ì •) ==="
echo
echo "âœ… ë¹Œë“œ êµ¬ì„±:"
echo "   - PyTorch 2.9.0 nightly + CUDA 12.8"
echo "   - vLLM 0.11.0 ì†ŒìŠ¤ ë¹Œë“œ"
echo "   - FlashAttention v2 (ìë™ í¬í•¨)"
echo "   - TORCH_CUDA_ARCH_LIST=12.0"
echo
echo "â±ï¸  ì˜ˆìƒ ì‹œê°„: 30-45ë¶„"
echo "ğŸ’¾ í•„ìš” ê³µê°„: ~15GB"
echo

# ì´ì „ ë¡œê·¸ ë°±ì—…
if [ -f /tmp/rtx5090-build.log ]; then
    mv /tmp/rtx5090-build.log /tmp/rtx5090-build.log.bak
    echo "ğŸ“ ì´ì „ ë¡œê·¸ ë°±ì—…: /tmp/rtx5090-build.log.bak"
fi

echo
echo "ğŸ”¨ ë¹Œë“œ ì‹œì‘..."
echo

# Docker ë¹Œë“œ ì‹¤í–‰
docker build \
    -f Dockerfile.rtx5090-working \
    -t vllm-rtx5090:v0.11.0 \
    --progress=plain \
    --build-arg MAX_JOBS=8 \
    . 2>&1 | tee /tmp/rtx5090-build.log

BUILD_EXIT_CODE=${PIPESTATUS[0]}

echo
if [ $BUILD_EXIT_CODE -eq 0 ]; then
    echo "âœ… ë¹Œë“œ ì™„ë£Œ!"
    echo
    echo "ğŸ“¦ ì´ë¯¸ì§€: vllm-rtx5090:v0.11.0"
    echo "ğŸ“‹ ë¡œê·¸: /tmp/rtx5090-build.log"
    echo
    echo "ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ë ¹:"
    echo "  docker run --gpus all -p 8002:8000 \\"
    echo "    -v /home/gpt-oss/models:/models \\"
    echo "    vllm-rtx5090:v0.11.0"
    echo

    # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
    echo "ğŸ“Š ì´ë¯¸ì§€ ì •ë³´:"
    docker images vllm-rtx5090:v0.11.0 --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}"
else
    echo "âŒ ë¹Œë“œ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: $BUILD_EXIT_CODE)"
    echo "ğŸ“‹ ë¡œê·¸ í™•ì¸: /tmp/rtx5090-build.log"
    echo
    echo "ë§ˆì§€ë§‰ 20ì¤„:"
    tail -20 /tmp/rtx5090-build.log
    exit 1
fi
