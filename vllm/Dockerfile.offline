FROM nvidia/cuda:12.6.3-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-dev python3-venv \
    git curl ca-certificates build-essential ninja-build cmake jq \
 && rm -rf /var/lib/apt/lists/*

RUN python3 -m pip install --upgrade pip

# RTX 5090 (Blackwell) 아키텍처 설정
ENV TORCH_CUDA_ARCH_LIST="9.0+PTX"
ENV CUDA_VISIBLE_DEVICES=0

# PyTorch CUDA 12.4 설치
RUN pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# vLLM 및 관련 패키지 설치
RUN pip install --no-cache-dir \
    vllm \
    transformers \
    accelerate \
    sentencepiece \
    protobuf \
    ray[serve]

WORKDIR /app

ENV VLLM_LOGGING_LEVEL=INFO

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]