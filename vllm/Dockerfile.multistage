# Stage 1: Base image with pre-downloaded packages
FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04 AS base

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip git curl ca-certificates \
 && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN python3 -m pip install --upgrade pip

# Stage 2: Download and cache dependencies
FROM base AS deps

WORKDIR /deps

# Download torch and dependencies first (these are large and rarely change)
RUN pip download torch==2.5.1 --index-url https://download.pytorch.org/whl/cu124 -d /deps/torch

# Download vllm and its dependencies
RUN pip download vllm -d /deps/vllm

# Stage 3: Final runtime image
FROM base AS runtime

# Copy downloaded packages from deps stage
COPY --from=deps /deps/torch /tmp/torch
COPY --from=deps /deps/vllm /tmp/vllm

# Install from local packages (much faster)
RUN pip install --no-index --find-links /tmp/torch torch==2.5.1 && \
    pip install --no-index --find-links /tmp/vllm --find-links /tmp/torch vllm && \
    rm -rf /tmp/torch /tmp/vllm

# RTX 5090 설정
ENV CUDA_VISIBLE_DEVICES=0
ENV VLLM_LOGGING_LEVEL=INFO
ENV TORCH_CUDA_ARCH_LIST="8.9"

WORKDIR /app

EXPOSE 8000

# 기본 엔트리포인트
ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server", \
            "--model", "facebook/opt-125m", \
            "--dtype", "auto", \
            "--host", "0.0.0.0", \
            "--port", "8000"]