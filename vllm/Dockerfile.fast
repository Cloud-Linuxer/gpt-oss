FROM nvidia/cuda:12.6.3-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-dev python3-venv \
    git curl ca-certificates build-essential ninja-build cmake jq \
 && rm -rf /var/lib/apt/lists/*

RUN python3 -m pip install --upgrade pip && pip install uv

# RTX 5090 (Blackwell) 아키텍처 설정
ENV TORCH_CUDA_ARCH_LIST="9.0;12.0+PTX"
ENV CUDA_VISIBLE_DEVICES=0
ENV VLLM_ATTENTION_BACKEND=FLASHINFER

# 사전 다운로드된 패키지 복사 (있는 경우)
COPY deps/wheels/ /tmp/wheels/

# 로컬 wheel 파일 우선 설치, 없으면 온라인에서 다운로드
RUN if [ -d /tmp/wheels ] && [ "$(ls -A /tmp/wheels)" ]; then \
        echo "사전 다운로드된 패키지 사용" && \
        pip install /tmp/wheels/*.whl && \
        pip install --no-cache-dir \
            vllm transformers accelerate sentencepiece protobuf ray[serve]; \
    else \
        echo "온라인에서 패키지 다운로드" && \
        pip install --no-cache-dir \
            torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 && \
        pip install --no-cache-dir \
            vllm transformers accelerate sentencepiece protobuf ray[serve]; \
    fi && \
    rm -rf /tmp/wheels

WORKDIR /app

# vllm 로깅 설정
ENV VLLM_LOGGING_LEVEL=INFO

EXPOSE 8000

# 헬스체크
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# 기본 엔트리포인트 - 환경변수로 설정 가능
ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]