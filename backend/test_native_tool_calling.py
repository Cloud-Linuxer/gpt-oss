#!/usr/bin/env python3
"""Native tool calling test - OpenAI format exactly as examples."""

import httpx
import json
import asyncio
from typing import Dict, Any

VLLM_URL = "http://localhost:8000/v1/chat/completions"

async def test_native_openai_format():
    """Test 1) Native approach - exactly as OpenAI examples."""
    
    print("ğŸ”¬ Testing Native Tool Calling (OpenAI Format)")
    print("=" * 70)
    
    # Exact format from OpenAI docs
    request_data = {
        "model": "openai/gpt-oss-20b",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant that calls functions when needed."},
            {"role": "user", "content": "ì„œìš¸ì˜ í˜„ì¬ ê¸°ì˜¨ì„ ì„­ì”¨ë¡œ ì•Œë ¤ì¤˜"}
        ],
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒí•œë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {"type": "string", "description": "ë„ì‹œëª…, ì˜ˆ: ì„œìš¸"},
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                        },
                        "required": ["location"]
                    }
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0
    }
    
    print("ğŸ“¤ Request:")
    print(json.dumps(request_data, indent=2, ensure_ascii=False))
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(VLLM_URL, json=request_data)
            print(f"\nğŸ“¥ Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("ğŸ“¦ Response:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                
                # Check for tool calls
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]
                    
                    if "tool_calls" in message and len(message["tool_calls"]) > 0:
                        print("\nâœ… SUCCESS: Native tool calling works!")
                        for call in message["tool_calls"]:
                            print(f"  ğŸ”§ Tool: {call['function']['name']}")
                            print(f"  ğŸ“ Args: {call['function']['arguments']}")
                        return True, result
                    else:
                        print(f"\nâŒ No tool calls detected")
                        print(f"Content: {message.get('content', 'No content')}")
                        if "reasoning_content" in message:
                            print(f"Reasoning: {message['reasoning_content']}")
                        return False, result
                else:
                    print("âŒ No choices in response")
                    return False, result
            else:
                print(f"âŒ HTTP Error: {response.status_code}")
                print(f"Response: {response.text}")
                return False, {"error": response.text}
                
        except Exception as e:
            print(f"âŒ Request failed: {e}")
            return False, {"error": str(e)}


async def test_simple_calculator():
    """Test simple calculator call."""
    
    print("\nğŸ§® Testing Calculator Tool")
    print("=" * 70)
    
    request_data = {
        "model": "openai/gpt-oss-20b",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant that calls functions when needed."},
            {"role": "user", "content": "25 ê³±í•˜ê¸° 4ëŠ” ì–¼ë§ˆì•¼? ê³„ì‚°í•´ì¤˜."}
        ],
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "calculator",
                    "description": "ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•œë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "expression": {"type": "string", "description": "ê³„ì‚°í•  ìˆ˜ì‹"}
                        },
                        "required": ["expression"]
                    }
                }
            }
        ],
        "tool_choice": "auto",
        "temperature": 0
    }
    
    print("ğŸ“¤ Request:")
    print(json.dumps(request_data, indent=2, ensure_ascii=False))
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(VLLM_URL, json=request_data)
            print(f"\nğŸ“¥ Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("ğŸ“¦ Response:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]
                    
                    if "tool_calls" in message and len(message["tool_calls"]) > 0:
                        print("\nâœ… Calculator tool call detected!")
                        return True, result
                    else:
                        print(f"\nâŒ No tool calls")
                        print(f"Direct answer: {message.get('content', 'No content')}")
                        return False, result
                        
        except Exception as e:
            print(f"âŒ Request failed: {e}")
            return False, {"error": str(e)}
    
    return False, {}


async def test_no_tools_baseline():
    """Test same request without tools to compare."""
    
    print("\nğŸ“ Baseline Test (No Tools)")
    print("=" * 70)
    
    request_data = {
        "model": "openai/gpt-oss-20b",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "ì„œìš¸ì˜ í˜„ì¬ ê¸°ì˜¨ì„ ì„­ì”¨ë¡œ ì•Œë ¤ì¤˜"}
        ],
        "temperature": 0
    }
    
    print("ğŸ“¤ Request (No Tools):")
    print(json.dumps(request_data, indent=2, ensure_ascii=False))
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(VLLM_URL, json=request_data)
            print(f"\nğŸ“¥ Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("ğŸ“¦ Response:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return True, result
                
        except Exception as e:
            print(f"âŒ Request failed: {e}")
            return False, {"error": str(e)}
    
    return False, {}


async def main():
    """Run all native tool calling tests."""
    
    print("ğŸ§ª NATIVE TOOL CALLING TESTS")
    print("=" * 80)
    print("Testing gpt-oss-20b native tool calling capability")
    print("Following exact OpenAI format from documentation")
    print("=" * 80)
    
    results = {}
    
    # Test 1: Weather function call
    print("Test 1: Weather Function Call")
    results["weather"] = await test_native_openai_format()
    
    # Test 2: Calculator function call  
    print("\nTest 2: Calculator Function Call")
    results["calculator"] = await test_simple_calculator()
    
    # Test 3: Baseline without tools
    print("\nTest 3: Baseline Without Tools")
    results["baseline"] = await test_no_tools_baseline()
    
    # Summary
    print("\n" + "=" * 80)
    print("ğŸ“Š NATIVE TOOL CALLING TEST RESULTS")
    print("=" * 80)
    
    success_count = 0
    for test_name, (success, response) in results.items():
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        print(f"{test_name:<15} {status}")
        if success:
            success_count += 1
    
    print(f"\nOverall Success Rate: {success_count}/3")
    
    if success_count > 0:
        print("ğŸ‰ Native tool calling is partially working!")
        print("â†’ Can proceed with native implementation")
    else:
        print("ğŸš¨ Native tool calling completely failed")  
        print("â†’ Must implement emulation approach")
    
    # Save results
    with open("native_tool_test_results.json", "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": "2025-09-12T23:15:00Z",
            "model": "openai/gpt-oss-20b", 
            "vllm_version": "v0.10.1.1",
            "success_rate": f"{success_count}/3",
            "results": {name: {"success": success, "response": response} 
                       for name, (success, response) in results.items()}
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Results saved to: native_tool_test_results.json")
    
    return success_count > 0


if __name__ == "__main__":
    asyncio.run(main())