#!/usr/bin/env python3
"""Test forced function call with specific function name."""

import httpx
import json
import asyncio

VLLM_URL = "http://localhost:8000/v1/chat/completions"

async def test_forced_function_call():
    """Test (A) forced tool choice with specific function name."""
    
    print("ğŸ¯ Testing Strategy A: Forced Function Call")
    print("=" * 60)
    
    # Define calculator tool
    tools = [{
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "Perform mathematical calculations",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "Mathematical expression to evaluate"
                    }
                },
                "required": ["expression"]
            }
        }
    }]
    
    # Test request with forced function call
    request_data = {
        "model": "openai/gpt-oss-20b",
        "messages": [
            {"role": "system", "content": "ì •í™•ì„±ì„ ìœ„í•´ ê°€ëŠ¥í•˜ë©´ í•­ìƒ ë„êµ¬ë¥¼ ìš°ì„  ì‚¬ìš©í•œë‹¤."},
            {"role": "user", "content": "ê³„ì‚°í•´ì¤˜: 25 * 4 + 10"}
        ],
        "tools": tools,
        "tool_choice": {
            "type": "function",
            "function": {"name": "calculator"}
        },
        "parallel_tool_calls": False,
        "temperature": 0
    }
    
    print("ğŸ“¡ Request:")
    print(json.dumps(request_data, indent=2, ensure_ascii=False))
    print("\nğŸ”„ Sending...")
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(VLLM_URL, json=request_data)
            print(f"\nğŸ“¥ Response Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("ğŸ“¦ Response:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]
                    
                    if "tool_calls" in message and len(message["tool_calls"]) > 0:
                        print("\nâœ… SUCCESS: Tool calls detected!")
                        for call in message["tool_calls"]:
                            print(f"  ğŸ”§ Tool: {call['function']['name']}")
                            print(f"  ğŸ“ Args: {call['function']['arguments']}")
                        return True
                    else:
                        print(f"\nâŒ FAILED: No tool calls")
                        print(f"Content: {message.get('content', 'No content')}")
                        return False
                else:
                    print("âŒ FAILED: No choices in response")
                    return False
            else:
                print(f"âŒ HTTP Error: {response.status_code}")
                print(f"Response: {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Request failed: {e}")
            return False


async def test_complex_weather_task():
    """Test (B) complex task that requires tools."""
    
    print("\nğŸŒ¤ï¸  Testing Strategy B: Complex Weather Task")
    print("=" * 60)
    
    # Define weather tool
    tools = [{
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "ë„ì‹œ í˜„ì¬ ë‚ ì”¨ ì¡°íšŒ",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string"},
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                },
                "required": ["location"]
            }
        }
    }]
    
    request_data = {
        "model": "openai/gpt-oss-20b",
        "messages": [
            {"role": "system", "content": "ì§ì ‘ ê³„ì‚°í•˜ì§€ ë§ê³ , ì œê³µëœ ë„êµ¬ë¥¼ ìš°ì„  ì‚¬ìš©í•œë‹¤."},
            {"role": "user", "content": "ì„œìš¸Â·ë¶€ì‚°Â·ë‰´ìš•ì˜ í˜„ì¬ ê¸°ì˜¨ê³¼ ì²´ê°ì˜¨ë„ë¥¼ ì„­ì”¨ë¡œ ì¡°íšŒí•´ í‰ê· /ìµœëŒ“ê°’ì„ í•¨ê»˜ ìš”ì•½í•´ì¤˜. ê° ë„ì‹œëŠ” ë°˜ë“œì‹œ get_weather í•¨ìˆ˜ë¡œ ì¡°íšŒí•´."}
        ],
        "tools": tools,
        "tool_choice": "auto",
        "parallel_tool_calls": True,
        "temperature": 0
    }
    
    print("ğŸ“¡ Request:")
    print(json.dumps(request_data, indent=2, ensure_ascii=False))
    print("\nğŸ”„ Sending...")
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(VLLM_URL, json=request_data)
            print(f"\nğŸ“¥ Response Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("ğŸ“¦ Response:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]
                    
                    if "tool_calls" in message and len(message["tool_calls"]) > 0:
                        print(f"\nâœ… SUCCESS: {len(message['tool_calls'])} tool calls detected!")
                        for i, call in enumerate(message["tool_calls"]):
                            print(f"  ğŸ”§ Tool #{i+1}: {call['function']['name']}")
                            print(f"  ğŸ“ Args: {call['function']['arguments']}")
                        return True
                    else:
                        print(f"\nâŒ FAILED: No tool calls")
                        print(f"Content: {message.get('content', 'No content')}")
                        return False
                else:
                    print("âŒ FAILED: No choices in response")
                    return False
            else:
                print(f"âŒ HTTP Error: {response.status_code}")
                print(f"Response: {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Request failed: {e}")
            return False


async def test_system_info_forced():
    """Test forced system info call."""
    
    print("\nğŸ’» Testing Strategy C: Forced System Info")
    print("=" * 60)
    
    tools = [{
        "type": "function",
        "function": {
            "name": "system_info",
            "description": "Get system information",
            "parameters": {
                "type": "object",
                "properties": {
                    "info_type": {
                        "type": "string",
                        "enum": ["all", "cpu", "memory", "disk"],
                        "description": "Type of system info to retrieve"
                    }
                },
                "required": []
            }
        }
    }]
    
    request_data = {
        "model": "openai/gpt-oss-20b",
        "messages": [
            {"role": "system", "content": "ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒëŠ” ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ì‚¬ìš©í•œë‹¤."},
            {"role": "user", "content": "í˜„ì¬ ì‹œìŠ¤í…œì˜ CPUì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì•Œë ¤ì¤˜"}
        ],
        "tools": tools,
        "tool_choice": {
            "type": "function",
            "function": {"name": "system_info"}
        },
        "temperature": 0
    }
    
    print("ğŸ“¡ Request:")
    print(json.dumps(request_data, indent=2, ensure_ascii=False))
    print("\nğŸ”„ Sending...")
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            response = await client.post(VLLM_URL, json=request_data)
            print(f"\nğŸ“¥ Response Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print("ğŸ“¦ Response:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]
                    
                    if "tool_calls" in message and len(message["tool_calls"]) > 0:
                        print(f"\nâœ… SUCCESS: Tool calls detected!")
                        for call in message["tool_calls"]:
                            print(f"  ğŸ”§ Tool: {call['function']['name']}")
                            print(f"  ğŸ“ Args: {call['function']['arguments']}")
                        return True
                    else:
                        print(f"\nâŒ FAILED: No tool calls")
                        print(f"Content: {message.get('content', 'No content')}")
                        return False
                else:
                    print("âŒ FAILED: No choices in response")
                    return False
            else:
                print(f"âŒ HTTP Error: {response.status_code}")
                print(f"Response: {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Request failed: {e}")
            return False


async def main():
    """Run all tests."""
    print("ğŸ§ª vLLM Tool Calling Diagnosis")
    print("=" * 80)
    print("Key insight: gpt-oss model auto-enables tool use per logs")
    print("Testing forced function calls vs. complexity induction")
    print("=" * 80)
    
    results = {}
    
    # Test A: Forced function call
    results["forced_calculator"] = await test_forced_function_call()
    
    # Test B: Complex weather task
    results["complex_weather"] = await test_complex_weather_task()
    
    # Test C: Forced system info
    results["forced_system_info"] = await test_system_info_forced()
    
    print("\n" + "=" * 80)
    print("ğŸ“Š SUMMARY")
    print("=" * 80)
    
    for test_name, success in results.items():
        status = "âœ… SUCCESS" if success else "âŒ FAILED"
        print(f"{test_name:<20} {status}")
    
    total_success = sum(results.values())
    print(f"\nOverall: {total_success}/3 tests passed")
    
    if total_success > 0:
        print("ğŸ‰ Tool calling IS working with the right approach!")
    else:
        print("ğŸš¨ Tool calling still not working - may need server restart with parser")


if __name__ == "__main__":
    asyncio.run(main())