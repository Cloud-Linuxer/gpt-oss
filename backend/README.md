# VLLM Function Call Agent

VLLM ê¸°ë°˜ í‘ì…˜ì½œ ì—ì´ì „íŠ¸ ë°±ì—”ë“œ ì„œë¹„ìŠ¤

## ğŸ”§ í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜

ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë“¤ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
# VLLM ì„¤ì •
VLLM_BASE_URL=http://your-vllm-server:port
VLLM_MODEL=your-model-name
VLLM_MAX_TOKENS=1000
VLLM_TEMPERATURE=0.7

# ê¸°ë³¸ ì„¤ì •ë§Œ (Kubernetes ë„êµ¬ ì œê±°ë¨)

# ê¸°íƒ€ ì„¤ì •
ENV=development
PORT=8080
LOG_LEVEL=INFO
```

### ğŸš¨ ë³´ì•ˆ ì£¼ì˜ì‚¬í•­

**ì ˆëŒ€ í•˜ë“œì½”ë”©í•˜ì§€ ë§ ê²ƒ:**
- VLLM ì„œë²„ ì ‘ì† ì •ë³´
- API í‚¤ë‚˜ í† í°
- ê¸°íƒ€ ë¯¼ê°í•œ ì„¤ì •ê°’ë“¤

**ê¶Œì¥ ë°©ë²•:**
1. `.env` íŒŒì¼ ì‚¬ìš© (gitignoreì— í¬í•¨ë¨)
2. ì»¨í…Œì´ë„ˆ í™˜ê²½ë³€ìˆ˜
3. Kubernetes Secrets
4. ì™¸ë¶€ ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ

### ğŸ“¦ ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ì‹¤í–‰
python app.py
```

### ğŸ§ª ë¹ ë¥¸ ì‚¬ìš© ì˜ˆì‹œ (cURL)

```bash
# 1) gpt-oss ëª¨ë¸ê³¼ ì±„íŒ… (íˆ´ ì‚¬ìš© ê°€ëŠ¥)
curl -sS -X POST http://localhost:8080/api/chat \
  -H 'Content-Type: application/json' \
  -d '{"message": "https://example.com ì„ GET ìš”ì²­í•´ì¤˜"}' | jq .

# 2) LangChain ì—ì´ì „íŠ¸ ëŒ€í™” (ReAct)
curl -sS -X POST http://localhost:8080/api/agent_chat \
  -H 'Content-Type: application/json' \
  -d '{"message": "í˜„ì¬ ì„œìš¸ ì‹œê°„ì„ ì•Œë ¤ì¤˜"}' | jq .

# 3) ë“±ë¡ëœ ë„êµ¬ ëª©ë¡ í™•ì¸
curl -sS http://localhost:8080/api/tools | jq .
```

#### Responses API íˆ´ í˜¸ì¶œ ì˜ˆì‹œ

```bash
# íˆ´ ë“±ë¡ + ì§ˆë¬¸
curl -sS -X POST "$BASE/v1/responses" -H "Authorization: Bearer $KEY" -H "Content-Type: application/json" -d '{
  "model": "openai/gpt-oss-20b",
  "input": "ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?",
  "tools": [
    {"type":"function","name":"get_weather","parameters":{"type":"object","properties":{"city":{"type":"string"}},"required":["city"]}}
  ]
}'

# ì‘ë‹µì—ì„œ function_call ì˜ call_id ì™€ arguments íŒŒì‹± í›„ íˆ´ ì‹¤í–‰ â†’ ê²°ê³¼ ì „ë‹¬
curl -sS -X POST "$BASE/v1/responses" -H "Authorization: Bearer $KEY" -H "Content-Type: application/json" -d "{
  \"model\": \"openai/gpt-oss-20b\",
  \"previous_response_id\": \"${RESP_ID}\",
  \"input\": [{\"type\":\"function_call_output\",\"call_id\":\"${CALL_ID}\",\"output\":\"{\\\"city\\\":\\\"Seoul\\\",\\\"temp_c\\\":27}\"}],
  \"tools\": [{\"type\":\"function\",\"name\":\"get_weather\",\"parameters\":{\"type\":\"object\",\"properties\":{\"city\":{\"type\":\"string\"}},\"required\":[\"city\"]}}]
}"
```

### ğŸ³ Docker ì‹¤í–‰

```bash
# ë¹Œë“œ
docker build -t vllm-function-agent .

# ì‹¤í–‰ (í™˜ê²½ë³€ìˆ˜ ì „ë‹¬)
docker run -d -p 8080:8080 \
  -e VLLM_BASE_URL=http://your-vllm-server:port \
  -e VLLM_MODEL=your-model-name \
  -e K8S_HOST=your-k8s-host \
  -e K8S_USER=your-k8s-user \
  -e K8S_PASSWORD=your-k8s-password \
  --name vllm-agent vllm-function-agent
```

## ğŸ› ï¸ ê¸°ëŠ¥

### MCP ë„êµ¬ë“¤
- **http_request**: ì‚¬ë‚´/ì™¸ë¶€ HTTP API í˜¸ì¶œ
- **time_now**: ì§€ì •ëœ ì‹œê°„ëŒ€ì˜ í˜„ì¬ ì‹œê° ë°˜í™˜

### OSS ëª¨ë¸ ë„êµ¬ ì‚¬ìš©
- ì¼ë¶€ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì€ ìµœì‹  `tools` í•„ë“œë¥¼ ì§€ì›í•˜ì§€ ì•Šì•„ 500 ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- í´ë¼ì´ì–¸íŠ¸ëŠ” ìë™ìœ¼ë¡œ ê¸°ì¡´ `functions` í•„ë“œë¡œ ì¬ì‹œë„í•˜ì—¬ ë„êµ¬ í˜¸ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤.

### API ì—”ë“œí¬ì¸íŠ¸
- `GET /health` - ì„œë¹„ìŠ¤ ìƒíƒœ
- `GET /api/tools` - ë“±ë¡ëœ ë„êµ¬ ëª©ë¡
- `POST /api/chat` - gpt-oss ëª¨ë¸ê³¼ ì±„íŒ… (íˆ´ ì‚¬ìš©)
- `POST /api/agent_chat` - LangChain ReAct ì—ì´ì „íŠ¸ì™€ ì±„íŒ… (vLLM OpenAI API ì‚¬ìš©)

## ğŸ”’ ë³´ì•ˆ

ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ë¯¼ê°í•œ ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ:

1. **í™˜ê²½ë³€ìˆ˜ë¡œë§Œ** ë¯¼ê°í•œ ì •ë³´ ê´€ë¦¬
2. **ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ** ì„¤ì • (VPN, ë°©í™”ë²½)
3. **ì ‘ê·¼ ê¶Œí•œ** ìµœì†Œí™”
4. **ë¡œê·¸ ëª¨ë‹ˆí„°ë§** í•„ìˆ˜
5. **ì •ê¸°ì ì¸ ë³´ì•ˆ ì—…ë°ì´íŠ¸**


